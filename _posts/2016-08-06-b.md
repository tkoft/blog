---
layout: post
---

***TL;DR:*   You'll hear people call the HoloLens "revolutionary" or "the future".  You'll think, "Oh yeah, of course, neat."  Let me really get the idea across for you; wearable AR like HoloLens will change the nature of computing as much as smartphones did to it a few years ago.**

>"The future of computing? It sure feels like it."  -*[TechRadar](http://www.techradar.com/us/reviews/wearables/microsoft-hololens-1281834/review)*

When I first heard about HoloLens, first read the announcement articles, I was excited, but not...convicted.  "Neat."  

>"The future is here..."  -*[The Verge](http://www.theverge.com/2016/4/1/11334488/microsoft-hololens-video-augmented-reality-ar-headset-hands-on)*

Augmented reality wasn't a new concept by any means; the press photos and screenshots (what do you call them on a HoloLens?  Vision-shots?) were pretty, but for the tech world that [hardly ever reflects the actual experience of using the product](http://mashable.com/2013/05/08/google-glass-pov/#exfRKJXGJGq6).  

>"Wearing a HoloLens feels like having a glimpse of an unfinished future." -*[IEEE Spectrum](http://spectrum.ieee.org/geek-life/reviews/review-see-the-future-through-microsofts-hololens-augmentedreality-glasses)*

Sure, AR is the future, and HoloLens is an AR device, so articles on consumer-oriented tech review sites are gonna make a big deal about it to get readers excited and clicking on links.


Putting on HoloLens the first time completely rewrote that story. 
<!--break-->

I was utterly unprepared for how polished, how usable, how *convincing* holograms were.  A 12-year-old could put together a device to [put some images in front of your eyes in 3D](https://vr.google.com/cardboard/), but HoloLens is an absolutely revolutionary piece of engineering, and I don't say that lightly.  The fact that Microsoft packaged the developer edition of HoloLens like a consumer-ready device didn't do it any harm either; I still remember taking the thing out of its black box with holographic embossed graphics and classy bright-blue inner lining, firing it up and going through the setup process---that part was cool, but what *really* changed my entire view on the future of human-computer interaction is when the calibrations finished. 


HoloLens mapped our intern room in our office in a few seconds, and I put a Microsoft Edge window on the wall.  It stayed there.  I could jerk my head in all directions, go to other rooms, even shift the device around on my head if it got uncomfortable, and it stuck to the wall as if [it had been nailed there](https://youtu.be/npjOSLCR2hE?t=116).  Think about the optical engineering, the graphics, the optimizations that go into making something like that possible.  It's not a task to be taken lightly, and because Microsoft didn't, they've proven to me that AR is indeed the future of computing.  When someone takes a screenshot of what they see with HoloLens, it doesn't look better--it looks *worse* than real life.

I think people who are around a lot of tech understand how easy it is to make a "proof of concept" for a new technology, and how significantly harder it is to make that proof of concept into something viable.  I imagine that if one of my 50+ year-old Chinese parents put on a HoloLens, they wouldn't be much more impressed (or perhaps even less impressed) with it than with the $2 Google Cardboard I showed them with my Nexus 5X in it.  Indeed, people like to draw false parallels between AR and VR.  This summer, the challenge my team of interns was given was to develop an AR **or** VR solution for the medical simulation training field.  But in absolutely every single facet, AR is a more complex and technically challenging task; VR is really a subset of AR.  I knew right off the bat that if our product was going to be something impactful and useful for real-life, VR wouldn't cut it for anything beyond presenting information in a prettier format.  Even [HoloLens's own demos show](https://www.youtube.com/watch?v=SKpKlh1-en0) it just presenting content in interactive 3D, which is cool, but not really impactful; it's just *mixed reality*, stacking virtual stuff on top of real world space (to make it cooler I guess).  You could do that with VR, with a smartphone in a piece of cardboard.  

I'm very glad that our team this summer found a way to use HoloLens in a way that *only* HoloLens can succeed, and no other technology--we're augmenting medical simulation manikins ([yes, that's the correct spelling](https://en.wikipedia.org/wiki/Manikin)) with holograms that cue students with symptoms or scenarios that previously could only be conveyed by the instructor interrupting the student.  We're using HoloLens to teach students to look for important physiological signs themselves, rather than being told that they're there (sometimes by a sticky note stuck to the $70,000 manikin) and later having to practice looking for cyanosis on your lips when you're not breathing in the ER.  The application responds to the manikin's vital signs automatically, so if the student does something that screws up the patient's breathing, we can show his lips and fingernails starting to turn blue.  It doesn't look like real-life cyanosis the way we've developed it in two months and the way HoloLens works right now, but try doing that with cardboard.

Anyway, writing this post has gotten me all riled up about AR's merits; what I came to do originally today was to talk about how *different* and *weird* it is developing for or even just talking about a device like HoloLens.

People don't realize that HoloLens is a Windows 10 device--it's its own computing device, as powerful as your smartphone,  not just some I/O hardware.  And it lives entirely in its own world of computing.  What I mean by that is when you're using or developing for HoloLens, you have to think entirely differently about what being a "computer program" is compared to what we're used to with 2D screens controlled by keyboard and mice.  It's not that it's less functional--again, it's running Windows 10--it's just an entirely different design language.  Which, incidentally, means the version of Windows 10 it's running has a lot of things stripped out since Windows 10 *wasn't* designed for use as holograms.  It's actually called "Windows 10 Holographic".  Learning the new language and mindset of HoloLens has been one of the coolest parts of this summer for me, and that's where I believe the future of human-computer interaction is going.  It'll be a dramatic shift.  It won't be easy.  But the benefits of AR make me believe it'll happen.  I don't think Microsoft's done the best job of defining that language right now (they've categorized all human input into "gaze", "voice", and "gesture"), but I don't blame them since they were limited to the hardware implementation they had.  But the AR language is something that will develop naturally though as AR becomes more commonplace; hopefully I can be a part of that, now that I've seen the other side!

When you write a program for AR, you can't just think about how it'll run with the inputs you define; you have to think about how it'll interact with any humanly possible environment on planet Earth, how it'll respond if the user even *looks* away, or talks, or moves their hands, or walks into another room.  Even a 2D program has some position in our 3D world, and you have to consider that.  The smartphone revolutionized what it means to be a computer in a way that no other category of device did since computers were invented; *I'm calling it now, wearable AR tech like HoloLens will be that next revolution.*  